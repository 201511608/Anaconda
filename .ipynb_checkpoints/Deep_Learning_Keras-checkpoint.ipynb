{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep_Learning_Keras \n",
    "#1 Arch : how many layers Activation\n",
    "#2 Compile :: loss and how it works\n",
    "#3 Fit :: Froword and Back \n",
    "#4 Predict\n",
    "\n",
    "#MIT Licensed\n",
    "\n",
    "#Scale Data :: Getting data in to similar average value\n",
    " \n",
    "#Regression       Y=f(x)\n",
    "#Classification  Predictiong from set of descrete Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1\n",
    "#import\n",
    "import numpy as np\n",
    "import pandas\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2\n",
    "#Import Data\n",
    "df = pandas.read_csv('hourly_wages.csv')\n",
    "predictors=np.delete(df.values,0,1) # Detete a Column  [1->column 0->row]\n",
    "target=df.values[:,0]\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3\n",
    "#1 Arch\n",
    "\n",
    "# Model 1)Sequential 2)  Check other models very complex connections  Very important   ??????????\n",
    "model = Sequential()\n",
    "\n",
    "# Dense :: All the Nodes in previous layers connect all the nodes in the current layer\n",
    "model.add(Dense(100, activation= 'relu',input_shape=(n_cols,))) # (n_cols,) = any no of rows\\data\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.4\n",
    "#Compile\n",
    "#2 Compile\n",
    "#Optimizer Learing rate\n",
    "#Adam is Best for Optimizer\n",
    "#loss function Mean SquareError\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "534/534 [==============================] - 1s 2ms/step - loss: 58.0580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc636fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.5\n",
    "#Fit\n",
    "#Do Forword and Backword Propogation\n",
    "model.fit(predictors, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.66553688],\n",
       "       [ 15.44150448],\n",
       "       [  7.3208952 ],\n",
       "       [  7.89049339],\n",
       "       [ 10.54580402],\n",
       "       [  9.23855114],\n",
       "       [ 12.20783901],\n",
       "       [  8.95649052],\n",
       "       [ 11.23385143],\n",
       "       [  8.95649052]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.6\n",
    "#prediction\n",
    "model.predict(predictors[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.8 \n",
    "#Saving \n",
    "model.save('model_hourly_wages.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.9\n",
    "#Loading Model\n",
    "my_model=load_model('model_hourly_wages.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#1.10\n",
    "#Check the Architure of Model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "#1.11\n",
    "# Print\n",
    "print(\"Loss function: \" + model.loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 45.4852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ca7d68>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "#Hourly_wages\n",
    "import numpy as np\n",
    "import pandas\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "#Import Data\n",
    "df = pandas.read_csv('hourly_wages.csv')\n",
    "predictors=np.delete(df.values,0,1) # Detete a Column  [1->column 0->row]\n",
    "target=df.values[:,0] # or # df.wage_per_hour\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation= 'relu',input_shape=(n_cols,))) \n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#compile\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#Fit\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values\n",
    "df.describe()\n",
    "df.index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[[ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "\n",
      " [0 1 2 3]\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "\n",
      " [ 0  1  2 13]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "# Categorical\n",
    "# Single -> Multi Column Convertion\n",
    "from keras.utils import to_categorical\n",
    "a=np.array([1,2,3])\n",
    "cat1=to_categorical(a)\n",
    "print(a)\n",
    "print(cat1)\n",
    "\n",
    "b=np.array([0,1,2,3])\n",
    "cat2=to_categorical(b)\n",
    "print(\"\\n\",b)\n",
    "print(cat2)\n",
    "\n",
    "c=np.array([0,1,2,13])\n",
    "cat3=to_categorical(c)\n",
    "print(\"\\n\",c)\n",
    "print(cat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "# Classification \n",
    "# To Select from Bunch of Options\n",
    "# Similar to Regression Only Few things are Different\n",
    "# Loss function :: Categorical_crossentropy\n",
    "# Log Loss\n",
    "# Metric = ['accuracy'] Print accuracy at end of each epoch\n",
    "# optimizer = 'sgd' 'adam'\n",
    "# Output  Have Softmax activation  = Pridiction Sum to One  :: To Check Proabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "891/891 [==============================] - 1s 896us/step - loss: 2.7872 - acc: 0.6117\n",
      "(891, 2)\n",
      "[  1.28296968e-02   1.11328884e-08   1.27289444e-02   1.36248514e-06\n",
      "   1.86100265e-03   3.09178862e-03   4.19693521e-07   8.00135825e-03\n",
      "   9.38659348e-03   3.82701925e-04   2.51540113e-02   2.67345877e-05\n",
      "   1.95582770e-02   1.35726135e-04   7.55440593e-02   1.09958426e-04\n",
      "   1.75570382e-03   4.28271433e-03   2.15733796e-03   4.86527942e-03\n",
      "   2.91439239e-04   1.79373124e-03   3.83989811e-02   4.89191407e-05\n",
      "   9.31888726e-03   2.09537786e-04   2.91590509e-03   9.12166102e-29\n",
      "   5.27806301e-03   5.50796837e-03   8.57923515e-05   4.00982512e-16\n",
      "   5.30519243e-03   1.12567623e-05   1.23638255e-09   3.86160792e-07\n",
      "   2.91541987e-03   1.66780539e-02   5.03538223e-03   1.94998458e-02\n",
      "   1.17231754e-03   1.69791630e-03   2.83911917e-03   2.16671266e-04\n",
      "   2.19660401e-02   5.47437137e-03   1.52767706e-03   5.30519243e-03\n",
      "   4.51396481e-04   6.52429787e-03   9.12567266e-05   1.67955663e-02\n",
      "   2.57708344e-09   5.39544213e-04   1.63443072e-08   6.57868659e-05\n",
      "   2.36038435e-02   2.74399202e-03   4.27112775e-03   2.62433714e-05\n",
      "   7.59866042e-03   1.85861260e-09   4.27010288e-10   2.95215938e-03\n",
      "   2.29085214e-04   1.66014081e-03   7.66508747e-03   2.29092576e-02\n",
      "   2.39121243e-02   5.30198822e-03   3.03621404e-03   2.92640871e-05\n",
      "   9.43636547e-09   2.14713509e-03   3.86117335e-07   9.04200505e-03\n",
      "   5.50796837e-03   5.47437137e-03   1.72655191e-03   5.32960333e-03\n",
      "   1.38617903e-02   4.49890736e-03   5.29730460e-03   3.75976651e-06\n",
      "   3.73312756e-02   1.27352425e-03   6.15887635e-04   5.47437137e-03\n",
      "   1.67881219e-28   1.03994533e-02   4.76557389e-03   1.96471456e-02\n",
      "   3.28710108e-08   1.90607295e-03   3.83407205e-05   5.47437137e-03\n",
      "   6.53925042e-07   1.90411299e-07   9.91396257e-04   2.47274584e-04\n",
      "   9.33776610e-03   5.50796837e-03   7.30118277e-09   2.48628156e-03\n",
      "   1.04581972e-03   5.60649950e-03   2.80040987e-02   5.53443749e-03\n",
      "   1.16923964e-03   6.23766857e-04   7.81476160e-07   9.99650173e-03\n",
      "   1.42294066e-02   2.24060547e-02   1.04407556e-02   1.67367067e-02\n",
      "   4.97254587e-06   9.93694179e-04   1.42564913e-27   2.65381415e-03\n",
      "   1.33841809e-08   5.47437137e-03   7.53995482e-05   3.66299856e-03\n",
      "   1.51943991e-09   1.57495458e-02   3.18012596e-03   1.07790902e-02\n",
      "   8.71910830e-04   3.97945172e-04   1.31894730e-03   2.00978499e-02\n",
      "   3.17848928e-04   5.39544213e-04   6.49532443e-03   4.01511090e-03\n",
      "   2.49188836e-03   4.90961213e-07   3.18580531e-02   2.89470892e-09\n",
      "   3.65165016e-03   2.38664299e-02   5.87472692e-03   1.37198167e-02\n",
      "   1.97406765e-02   1.05274055e-04   6.58068852e-03   6.94651273e-04\n",
      "   3.65130050e-04   5.71958022e-04   1.37430368e-04   1.06262831e-07\n",
      "   6.78903671e-05   5.80289634e-04   5.63692721e-03   4.07792342e-08\n",
      "   3.44544388e-02   4.07515466e-03   5.34292171e-03   1.08845875e-07\n",
      "   3.22604086e-04   9.64802224e-04   7.69865932e-03   2.92785559e-02\n",
      "   1.28937259e-04   1.03755966e-02   1.93761139e-06   1.48724546e-04\n",
      "   5.38891414e-04   3.95194320e-07   5.44403247e-06   1.46773108e-03\n",
      "   1.01925313e-01   1.67367067e-02   8.32161641e-06   2.32086461e-02\n",
      "   3.26325622e-04   3.89177476e-05   3.16755055e-03   1.46152463e-03\n",
      "   1.82705435e-07   2.03035981e-03   9.01460124e-04   9.10888484e-05\n",
      "   1.51722245e-02   2.23230199e-06   2.49749143e-03   1.05426159e-04\n",
      "   2.86378054e-04   1.60051766e-03   3.93246440e-03   1.36165190e-02\n",
      "   3.10548842e-02   1.98523956e-03   9.09061782e-05   1.89623281e-16\n",
      "   3.18012596e-03   5.95053600e-04   5.30519243e-03   1.22132804e-02\n",
      "   5.26073715e-03   1.08845875e-07   2.31607002e-03   1.92078005e-04\n",
      "   2.69494224e-02   1.05334364e-01   1.41465559e-03   1.49228715e-03\n",
      "   3.43998820e-02   4.47363273e-05   1.08181722e-02   1.14573538e-03\n",
      "   1.46403722e-02   3.16755055e-03   2.78281397e-03   1.47382757e-12\n",
      "   1.08974641e-02   1.07127555e-04   4.45294512e-09   4.05578595e-03\n",
      "   3.55918221e-02   4.86523705e-03   1.43823912e-04   5.50796837e-03\n",
      "   1.27303307e-10   1.35984877e-02   1.92309041e-02   1.84628721e-02\n",
      "   1.47303231e-02   4.78336297e-04   9.83172765e-10   4.81789187e-03\n",
      "   3.53772302e-05   1.97983929e-03   9.44356993e-03   9.30053554e-03\n",
      "   9.87334352e-05   4.95922565e-03   1.92309041e-02   2.21895054e-03\n",
      "   2.73593608e-03   2.49749143e-03   4.65520099e-03   1.47124864e-02\n",
      "   2.16919114e-03   1.06002152e-10   1.49515169e-02   1.21159460e-02\n",
      "   8.23839912e-07   2.34518484e-05   5.65092545e-03   6.22830167e-03\n",
      "   9.15083820e-06   1.83132885e-03   6.09338633e-04   3.06676072e-03\n",
      "   4.05775635e-09   8.17885093e-10   0.00000000e+00   9.25536006e-05\n",
      "   3.18012596e-03   1.54332968e-03   1.47177348e-09   1.39984756e-03\n",
      "   5.30519243e-03   1.62128441e-03   6.11495707e-05   7.87907373e-03\n",
      "   1.12198169e-16   4.08093571e-15   2.21853203e-04   7.75523623e-03\n",
      "   6.23012078e-04   8.74200996e-05   5.30519243e-03   5.99276406e-10\n",
      "   6.54533796e-04   7.40604894e-03   1.12176291e-03   1.05355983e-03\n",
      "   1.14783088e-05   5.61576616e-03   3.10101993e-02   2.29652710e-02\n",
      "   5.31284022e-04   1.27926422e-03   3.84697272e-03   1.42913079e-02\n",
      "   5.71958022e-04   1.37522565e-02   5.19184029e-09   2.10989462e-10\n",
      "   7.60948693e-04   1.68719832e-02   1.04629667e-02   2.29085214e-04\n",
      "   6.00236934e-03   1.35815738e-16   2.42100781e-04   7.40450191e-27\n",
      "   5.30519243e-03   4.00881981e-04   1.82529036e-02   4.30820091e-03\n",
      "   5.47437137e-03   7.62078190e-17   3.48961615e-12   2.06203912e-12\n",
      "   3.07200768e-04   3.86493099e-07   1.91123228e-09   2.00458974e-28\n",
      "   8.67870112e-04   5.60649950e-03   1.18994765e-04   1.27644977e-02\n",
      "   8.70558200e-04   8.20408895e-05   8.37659088e-18   2.13103461e-14\n",
      "   1.46403722e-02   6.55465759e-03   3.20618576e-03   5.84357418e-04\n",
      "   1.08845875e-07   5.24210437e-15   2.99425901e-05   2.22763186e-03\n",
      "   1.58547144e-03   1.48244851e-06   5.84294845e-04   7.80750634e-05\n",
      "   5.98899476e-17   2.84236250e-03   9.41627215e-15   5.50796837e-03\n",
      "   3.74840639e-08   9.01848176e-15   3.86960106e-04   2.02375995e-05\n",
      "   1.96351251e-03   1.69742907e-28   4.21002274e-03   6.49532443e-03\n",
      "   1.35017023e-03   1.22132804e-02   1.27649098e-03   4.10413090e-03\n",
      "   2.14089844e-02   6.05027366e-04   1.17400084e-02   7.69296894e-05\n",
      "   1.98636893e-02   2.53477250e-03   2.91590509e-03   5.26073715e-03\n",
      "   2.32444540e-06   1.68302120e-03   5.27806301e-03   5.27806301e-03\n",
      "   1.84458710e-04   1.58939787e-04   2.50767567e-04   1.93660799e-03\n",
      "   1.52767706e-03   4.20676777e-03   7.31742056e-10   4.86446591e-03\n",
      "   5.30519243e-03   3.91698336e-08   4.25815557e-07   2.46055890e-02\n",
      "   2.29652710e-02   1.39028102e-15   1.11966934e-02   2.18668772e-09\n",
      "   2.42373422e-02   3.48079510e-23   1.17621860e-02   2.31081173e-02\n",
      "   3.81756811e-25   7.06389248e-02   2.99389614e-03   1.56370936e-06\n",
      "   5.50796837e-03   7.71460140e-09   6.09105518e-05   2.22763186e-03\n",
      "   3.18275439e-03   1.71768218e-02   8.02134943e-13   1.67975500e-02\n",
      "   4.29036887e-03   8.75769238e-13   8.91789701e-03   1.43316081e-02\n",
      "   5.85693913e-03   9.34443233e-05   1.08829550e-02   7.17179058e-03\n",
      "   9.98158474e-04   7.61528686e-03   1.95059199e-02   2.48957006e-03\n",
      "   3.12951431e-02   6.64561638e-04   1.44501071e-04   1.20708719e-02\n",
      "   1.68073568e-02   4.78336297e-04   5.50796837e-03   3.29491752e-03\n",
      "   3.61513847e-10   7.40604894e-03   4.55066183e-04   9.11850762e-03\n",
      "   1.24597515e-04   2.98589449e-02   3.16755055e-03   6.62322808e-03\n",
      "   2.83911917e-03   9.67263710e-03   4.79880720e-03   5.02433628e-03\n",
      "   3.10434191e-03   5.65092545e-03   5.96702390e-04   1.10826455e-03\n",
      "   3.18012596e-03   2.97904480e-03   4.79833659e-04   4.10413090e-03\n",
      "   1.90459265e-04   3.22623700e-02   1.75996931e-07   4.38911223e-13\n",
      "   5.26631426e-04   4.42070095e-03   1.94208599e-27   3.53327976e-03\n",
      "   1.46703518e-04   1.78412665e-02   7.87907373e-03   6.93296269e-03\n",
      "   5.46081271e-03   2.68615996e-09   1.23195881e-02   2.87687493e-04\n",
      "   1.30531918e-02   2.65267918e-05   2.10321596e-04   1.33246358e-03\n",
      "   1.89346232e-04   7.35608172e-11   5.47437137e-03   2.47067632e-03\n",
      "   5.96744212e-06   2.53667213e-06   3.00473970e-04   3.18012596e-03\n",
      "   6.82120517e-05   2.17711972e-03   9.50958292e-06   2.22783317e-04\n",
      "   5.47437137e-03   1.20931887e-03   7.40604894e-03   2.15179389e-05\n",
      "   3.18328827e-03   1.89974457e-02   5.65092545e-03   1.13405392e-03\n",
      "   3.89414694e-04   7.40714651e-03   2.12062690e-02   1.35662458e-06\n",
      "   6.64561638e-04   4.34077205e-03   1.44853182e-02   7.33261704e-02\n",
      "   3.14012832e-05   7.40604894e-03   1.69932333e-04   3.54191543e-05\n",
      "   1.74877710e-10   4.78336297e-04   2.52219023e-10   6.81985102e-06\n",
      "   4.07515466e-03   1.99887846e-02   1.33246358e-03   1.70900337e-02\n",
      "   1.71543143e-05   9.57375192e-08   1.66780539e-02   2.08967784e-03\n",
      "   7.99316835e-10   3.44430469e-03   2.26550582e-16   1.05043566e-02\n",
      "   2.92785559e-02   1.60653088e-02   5.33068506e-03   2.13612174e-03\n",
      "   4.11114948e-10   1.25222716e-12   7.03437894e-04   4.82630450e-04\n",
      "   9.98221687e-04   3.99812308e-07   2.76754866e-03   5.47437137e-03\n",
      "   2.58402753e-04   7.53463141e-08   1.06295040e-02   2.31447739e-05\n",
      "   3.70408385e-03   5.46243682e-04   3.07308568e-04   2.99737393e-03\n",
      "   1.55095686e-10   1.42913079e-02   2.91590509e-03   1.74507775e-07\n",
      "   2.91541987e-03   4.54957335e-04   3.00473970e-04   7.35148451e-25\n",
      "   9.98158474e-04   6.80736406e-03   3.45274573e-03   2.91541987e-03\n",
      "   1.44932913e-02   1.32204173e-03   6.63129892e-03   5.25189098e-03\n",
      "   1.05426159e-04   6.84149092e-12   3.63900559e-03   1.10604187e-05\n",
      "   5.05624591e-08   1.41792302e-03   1.31207763e-03   2.90024735e-04\n",
      "   1.09675029e-12   7.26032704e-06   9.75953648e-04   2.26414134e-03\n",
      "   8.31939862e-04   1.54655514e-04   3.09965270e-12   5.59923530e-04\n",
      "   3.17012449e-03   7.59974634e-03   2.38497984e-02   9.15083820e-06\n",
      "   4.89289187e-06   2.09365903e-25   3.45526741e-09   1.12863746e-03\n",
      "   3.18012596e-03   8.54075304e-04   4.02156683e-03   5.47437137e-03\n",
      "   9.11850762e-03   6.25442364e-04   2.30452493e-02   3.50848283e-03\n",
      "   2.91541987e-03   3.00233834e-03   2.19400299e-05   4.66874127e-07\n",
      "   2.53323669e-04   5.30519243e-03   3.55918221e-02   9.98006854e-03\n",
      "   2.96009984e-03   4.38751670e-07   2.73483712e-03   2.99389614e-03\n",
      "   3.41069303e-04   3.42435368e-12   2.92748573e-05   1.09236635e-05\n",
      "   2.74835131e-03   1.29408351e-08   2.37142303e-04   2.62771499e-10\n",
      "   1.42294066e-02   5.47437137e-03   1.93083158e-03   1.18205068e-09\n",
      "   2.83817324e-04   5.02832048e-03   1.94666267e-04   3.55781143e-04\n",
      "   2.21445734e-04   2.02087438e-04   2.91590509e-03   7.43780788e-08\n",
      "   5.39292232e-04   5.50796837e-03   1.22735692e-05   4.52803128e-04\n",
      "   1.61277378e-04   8.16629501e-04   4.10020165e-03   2.20287082e-04\n",
      "   6.71171365e-05   5.59807384e-17   1.97848130e-04   5.69593348e-03\n",
      "   2.49749143e-03   3.18012596e-03   1.86100265e-03   4.43067478e-07\n",
      "   1.30668143e-03   4.77127638e-03   1.65796882e-04   7.11824046e-03\n",
      "   1.86422153e-03   3.24669628e-07   4.09389799e-03   1.67700183e-02\n",
      "   6.21611718e-03   6.06766116e-06   3.18192360e-05   5.01191222e-09\n",
      "   7.66192563e-03   3.18223704e-03   5.02816363e-07   1.46083737e-04\n",
      "   9.35097560e-05   9.80479270e-03   2.89488467e-03   6.93296269e-03\n",
      "   2.99389614e-03   3.55162221e-04   4.21334735e-05   2.51200236e-03\n",
      "   1.96471456e-02   3.91698336e-08   5.41115319e-03   4.83088229e-07\n",
      "   1.89974457e-02   1.61244240e-09   2.30452493e-02   5.10967266e-06\n",
      "   5.58406208e-03   2.05426347e-02   5.50796837e-03   3.31566087e-03\n",
      "   1.65039245e-02   5.28854365e-03   2.65317000e-02   1.26460282e-08\n",
      "   5.50796837e-03   1.47126650e-03   8.62970855e-03   5.08828494e-13\n",
      "   4.85257637e-15   4.51152126e-04   8.61793742e-05   1.62622472e-03\n",
      "   1.65717080e-02   6.53438503e-09   6.49532443e-03   5.53443749e-03\n",
      "   5.29844547e-04   2.45128717e-06   2.18674868e-05   1.17399827e-06\n",
      "   5.77547189e-06   2.74799066e-03   7.40604894e-03   2.71163564e-02\n",
      "   9.62091330e-03   3.67502235e-02   1.18894004e-05   0.00000000e+00\n",
      "   5.22422791e-03   4.20036050e-09   1.83069259e-02   2.02725023e-05\n",
      "   2.79583401e-06   3.16928017e-05   5.76888269e-05   1.92160569e-02\n",
      "   2.71036848e-02   1.54976363e-23   3.38015042e-07   4.72819209e-02\n",
      "   4.83088229e-07   4.74826107e-03   1.21685835e-05   1.15364339e-04\n",
      "   4.52803128e-04   5.30871190e-03   9.23311557e-13   6.29953109e-04\n",
      "   1.90975546e-25   2.79850268e-04   1.14537347e-02   5.17936144e-03\n",
      "   6.71951612e-03   2.11852806e-04   5.84874011e-04   1.60146737e-04\n",
      "   3.35871427e-17   1.66014081e-03   2.54253086e-06   4.82630450e-04\n",
      "   5.30346597e-07   4.50189644e-03   1.15730036e-04   2.31733210e-02\n",
      "   3.21283892e-25   1.01672290e-02   1.90724991e-03   2.57481169e-03\n",
      "   5.39123663e-04   2.73536704e-02   1.79373124e-03   1.62220487e-04\n",
      "   9.13685994e-07   1.92602053e-02   8.20982794e-04   5.30782016e-03\n",
      "   5.43974689e-04   1.30256927e-02   1.09544791e-23   3.78716271e-03\n",
      "   7.40604894e-03   8.62970855e-03   8.62970855e-03   2.84191594e-03\n",
      "   3.69342924e-05   0.00000000e+00   5.50796837e-03   5.50796837e-03\n",
      "   2.64196016e-04   1.55701596e-09   2.07198910e-28   3.84254404e-03\n",
      "   3.50177241e-03   2.80550871e-09   3.50185880e-03   5.22256549e-03\n",
      "   1.53210499e-06   2.02243635e-03   6.75312476e-03   4.20039184e-02\n",
      "   2.40397803e-03   1.22223264e-02   6.24076009e-08   3.39442976e-02\n",
      "   5.62879443e-03   1.97406765e-02   2.17711972e-03   6.25165586e-10\n",
      "   3.63900559e-03   7.52704102e-04   1.05032846e-02   1.33451529e-12\n",
      "   3.65314819e-02   2.64886135e-09   1.31075803e-05   3.65162129e-03\n",
      "   4.27969062e-04   2.94224476e-03   9.93145630e-03   2.38481225e-04\n",
      "   9.43601553e-05   2.91590509e-03   6.39538557e-05   2.71315910e-02\n",
      "   3.18012596e-03   3.98650691e-02   3.18170479e-03   4.50376216e-23\n",
      "   5.16866408e-02   1.04819856e-06   2.37495973e-04   9.42547747e-04\n",
      "   9.25904326e-03   9.18612722e-03   4.48396429e-02   1.02560024e-03\n",
      "   1.80315692e-02   8.19082469e-10   3.18012596e-03   8.05124466e-04\n",
      "   1.82705435e-07   1.35921451e-04   8.95455759e-03   8.91691481e-04\n",
      "   1.02614933e-04   5.66744898e-03   2.16882769e-03   8.36548978e-04\n",
      "   1.79373124e-03   5.17667504e-04   2.41120356e-13   1.16667524e-01\n",
      "   6.79827202e-03   3.52271693e-03   1.62974629e-03   4.44323830e-02\n",
      "   8.91691481e-04   1.48116260e-06   7.66444532e-03   2.92044744e-04\n",
      "   1.89675670e-03   1.85505999e-03   3.76826781e-03   9.80479270e-03\n",
      "   2.02846900e-02   2.06859004e-05   5.59999142e-04   1.76457479e-03\n",
      "   1.01825645e-10   6.35844097e-03   1.89733366e-03   8.75332393e-03\n",
      "   1.30366519e-04   3.28292837e-03   4.83088229e-07   3.07749840e-04\n",
      "   3.18012596e-03   4.13856782e-10   9.60945711e-03   1.19211655e-02\n",
      "   2.91541987e-03   1.22423992e-02   2.64131539e-02   1.10951082e-09\n",
      "   1.64182801e-02   5.47437137e-03   3.86117335e-07   1.61747404e-04\n",
      "   1.96136869e-02   2.80028600e-02   1.54716603e-04   1.10453810e-03\n",
      "   2.92785559e-02   6.32469484e-04   1.08845875e-07   9.63468861e-04\n",
      "   1.45225014e-04   5.15171961e-10   1.44602056e-03   3.54146914e-06\n",
      "   2.41242517e-02   1.02868195e-04   1.61559350e-04   4.11640368e-02\n",
      "   1.05724940e-17   4.41120173e-05   3.89049249e-03   2.91541987e-03\n",
      "   3.69337096e-04   1.05464933e-02   1.18661053e-04   1.82705435e-07\n",
      "   7.49903452e-03   9.55832016e-04   3.33876628e-03   1.58616035e-06\n",
      "   5.16825030e-03   5.79690263e-02   7.66192563e-03   9.09949449e-07\n",
      "   2.98980647e-03   2.72088742e-04   5.25165175e-04   3.80509980e-02\n",
      "   1.72552578e-02   2.30452493e-02   5.50796837e-03   5.21377885e-10\n",
      "   1.20237924e-03   2.56246421e-03   1.98632125e-02   5.36238309e-03\n",
      "   9.25904326e-03   2.37816610e-04   4.86523705e-03   4.69796651e-04\n",
      "   1.37344352e-03   1.51082248e-04   1.72874355e-03]\n"
     ]
    }
   ],
   "source": [
    "# 4.1\n",
    "# Titanic\n",
    "# sgd :: Stochastic Gradient descent\n",
    "#Output  : Dead or Alive    Yes or No\n",
    "import numpy as np\n",
    "import pandas\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Import Data\n",
    "df = pandas.read_csv('Titanic_data.csv')\n",
    "predictors=np.delete(df.values,0,1) # Detete a Column  [1->column 0->row]\n",
    "target=to_categorical(df.survived)\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "#\n",
    "model= Sequential()\n",
    "model.add(Dense(32,activation='relu',input_shape=(n_cols,)))\n",
    "model.add(Dense(2,activation='softmax')) # Survived or Died\n",
    "\n",
    "#\n",
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#\n",
    "model.fit(predictors, target)\n",
    "\n",
    "#\n",
    "predictions = model.predict(predictors)\n",
    "probability_true =predictions[:,1]\n",
    "print(predictions.shape)\n",
    "print(probability_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 38.0, 1, 0, 71.2833, 0, False, 1, 0, 0], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
