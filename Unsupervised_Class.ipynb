{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UnSupervised Class\n",
    "\n",
    "# My UnSupervised Learning Functions\n",
    "class Unsupervised:\n",
    "    \n",
    "    def __init__( self):\n",
    "        print(\"Unsupervised Instance Begin\") \n",
    "        \n",
    "    def __del__(self):\n",
    "       print(\"Unsupervised Instance Destroyed\")\n",
    "    \n",
    "    def check(self):\n",
    "        print(\"In Unsupervised class\")\n",
    "    \n",
    "    #plots\n",
    "    def Scatter_Plot(self,x,y,labels=[]):\n",
    "       # labels=[1 for i in range(len(x))]\n",
    "        plt.scatter(x,y,c=labels,alpha =0.75)\n",
    "       # plt.scatter(centroids[:,0],centroids[:,1],color='r',marker='D',s=50)\n",
    "        plt.show()\n",
    "        \n",
    "    def Scatter_Plot_WithCg(self,cgx,cgy,x,y,labels=[]):\n",
    "        # centroids=model.cluster_centers_  # centroids[:,0],centroids[:,1] \n",
    "        #labels=[1 for i in range(len(x))]\n",
    "        plt.scatter(x,y,c=labels,alpha =0.75)\n",
    "        plt.scatter(cgx,cgy,color='r',marker='D',s=50)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def Inertia_Cluster_Graph(self,Train_Data):\n",
    "        sm_data=Train_Data\n",
    "        ks = range(1, 15)\n",
    "        inertias = []\n",
    "        for k in ks:\n",
    "            # Create a KMeans instance with k clusters: model\n",
    "            modle=KMeans(n_clusters=k)    \n",
    "            # Fit model to samples\n",
    "            modle.fit(sm_data)  \n",
    "            # Append the inertia to the list of inertias\n",
    "            inertias.append(modle.inertia_)\n",
    "        plt.plot(ks, inertias, '-o')\n",
    "        plt.xlabel('Number of Clusters, k')\n",
    "        plt.ylabel('Inertia')\n",
    "        plt.xticks(ks)\n",
    "        plt.show() \n",
    "        \n",
    "        \n",
    "    def crosstable(predictedData,targetData):\n",
    "        import pandas as pd\n",
    "        ct=pd.crosstab(predictedData,targetData)\n",
    "        print(\"\\nCrossTable\\n\",ct)\n",
    "        \n",
    "    def Normalizer_Kmean(self,Train_Data,Prediction_Data,clusters=5):    \n",
    "        ##import numpy as np\n",
    "        from sklearn.preprocessing import Normalizer\n",
    "        from sklearn.cluster import KMeans\n",
    "\n",
    "        # Market_Data=pd.read_csv('sharemarket_data.csv',header=0,usecols= [x for x in range(1,963)])\n",
    "        ##companiessm_data=np.loadtxt('sharemarket_data.txt') #sharemarket_data\n",
    "        ##companies=pd.read_csv('sharemarket_data.csv',header=0,usecols= [0]).values.reshape(60)\n",
    "\n",
    "        #7.1\n",
    "        normalizer= Normalizer() # Normalizing the Data\n",
    "        kmeans= KMeans(n_clusters=clusters)   # Change Cluster and check the results\n",
    "        pipeline = make_pipeline(normalizer,kmeans)\n",
    "        pipeline.fit(Train_Data)\n",
    "\n",
    "        #7.2\n",
    "        prediction =pipeline.predict(Prediction_Data)\n",
    "        return prediction\n",
    "    \n",
    "    def StandardScaler_Kmean(self,Train_Data,Prediction_Data,clusters=5):                     \n",
    "            from sklearn.pipeline import make_pipeline\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            from sklearn.cluster import KMeans\n",
    "            \n",
    "            # StandardScaler  MaxAbsScalar   Normilizer\n",
    "            scaler = StandardScaler()\n",
    "            # Create KMeans instance: kmeans\n",
    "            kmeans = KMeans(n_clusters=clusters)\n",
    "\n",
    "\n",
    "            # Create pipeline: pipeline\n",
    "            pipeline = make_pipeline(scaler,kmeans)  # Make_pipeline\n",
    "            # Fit the pipeline to samples\n",
    "            pipeline.fit(samples)\n",
    "            # Calculate the cluster labels: labels\n",
    "            labels = pipeline.predict(samples)\n",
    "            prediction=labels\n",
    "            return prediction\n",
    "        \n",
    "        \n",
    "    def Dendgrogram_Plot(self,TrainData,labels,method='complete'):\n",
    "        #label=[1 for i in range(len(TrainData))]\n",
    "        \n",
    "        from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        # Calculate the linkage: mergings:: This performs hierarchical clustering\n",
    "        mergings = linkage(TrainData, method=method)\n",
    "\n",
    "        # Plot the dendrogram\n",
    "        dendrogram(mergings,labels=label,leaf_rotation=90,leaf_font_size=6)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def DendgrogramDistance_SubPlot(self,TrainData,labels,distance=5,method='complete'):\n",
    "        from scipy.cluster.hierarchy import linkage\n",
    "        from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "        samples=TrainData\n",
    "        varieties_=labels\n",
    "       # varieties=['Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Kama wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Rosa wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat', 'Canadian wheat']\n",
    "\n",
    "        #Measures distance.\n",
    "        mergings = linkage(samples,method =method)  # Using above samples\n",
    "\n",
    "        dendrogram(mergings,labels=varieties_,leaf_rotation=90,leaf_font_size=6,)\n",
    "        print(\"Full Dendrogram, No distance limits\")\n",
    "        plt.show()\n",
    "\n",
    "        #Extracting Intermediate Clusters!\n",
    "        labels_f = fcluster(mergings,distance,criterion='distance')\n",
    "        print (labels)\n",
    "        print (\"At distance\",distance,\"Division considered Above this all assign as Indivudial Number\")\n",
    "        dendrogram(mergings,labels=labels_f,leaf_rotation=90,leaf_font_size=6,)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    def AllPlots(self,samples,labels,distance):\n",
    "        \n",
    "        #Inertia Plot\n",
    "        Unsupervised.Inertia_Cluster_Graph(self,samples)\n",
    "\n",
    "        #Scatter Plot                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +\n",
    "        Unsupervised.Scatter_Plot(self,samples[:,0],samples[:,1],labels)\n",
    "        Unsupervised.Scatter_Plot(self,samples[:,2],samples[:,3],labels)\n",
    "\n",
    "        #DendroGram Plot\n",
    "        Unsupervised.DendgrogramDistance_SubPlot(self,samples,labels,distance=distance,method='complete')\n",
    "    \n",
    "    def Tsne(self,samples,labels,learning_rate=100):\n",
    "        from sklearn.manifold import TSNE\n",
    "        model = TSNE(learning_rate=learning_rate)\n",
    "        tsne_features = model.fit_transform(samples)\n",
    "        return tsne_features\n",
    "    def TsnePlot(self,samples,labels_numbers,learning_rate=100):\n",
    "        print(\"Sample input Ex :\",samples[0,:])\n",
    "        tsne_features=Unsupervised.Tsne(self,samples,labels,learning_rate=100)\n",
    "        xs = tsne_features[:,0]\n",
    "        ys = tsne_features[:,1]\n",
    "        print(\"Tsne Output Ex:\",tsne_features[0,:])\n",
    "        plt.scatter(xs, ys, c=labels_numbers)\n",
    "        plt.show()\n",
    "    def TsnePlotLabel(self,samples,labels_numbers,labels_name,learning_rate=100):       \n",
    "        tsne_features=Unsupervised.Tsne(self,samples,labels,learning_rate=100)\n",
    "        xs = tsne_features[:,0]\n",
    "        ys = tsne_features[:,1]\n",
    "        print(\"Sample input Ex :\",samples[0,:])\n",
    "        print(\"Tsne Output Ex:\",tsne_features[0,:])\n",
    "        plt.scatter(xs, ys, c=labels_numbers)\n",
    "        for x, y, company in zip(xs, ys, companies):\n",
    "            plt.annotate(company, (x, y), fontsize=5, alpha=0.75)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def Pca(self,TrainData):\n",
    "        grains=TrainData\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.decomposition import PCA\n",
    "        \n",
    "        model=PCA()\n",
    "        model.fit(grains)\n",
    "        transformed=model.transform(grains)\n",
    "        ## we can use both to gether  FIT AND TRANSFORM\n",
    "        #  model.fit_transform(grains)\n",
    "        #14.1\n",
    "        print(\"Actual Data\")\n",
    "        plt.scatter(grains[:,0], grains[:,1])\n",
    "        #plt.axis('equal')\n",
    "        plt.show()\n",
    "\n",
    "        #14.2\n",
    "        print(\"\\n PCA Transformed \\n Data Shift to Mean=0  and Rotates\")\n",
    "        plt.scatter(transformed[:,0], transformed[:,1])\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "\n",
    "        #print\n",
    "        print(\"\\n\\nActual Data :\",grains[0,:])\n",
    "        print(\"PCA Transformed Data :\",transformed[0,:])\n",
    "        print(\"Mean of NotTransformed Data:\",model.mean_)\n",
    "        \n",
    "        \n",
    "        mean = model.mean_\n",
    "        print(\"\\n\\nmean :\",mean)\n",
    "\n",
    "        # Get the first principal component: first_pc\n",
    "        first_pc = model.components_[0,:]\n",
    "        print(\"first_pc\",first_pc)\n",
    "        print(\"The first principal component of the data is the direction in which the data varies the most\")\n",
    "        # Plot first_pc as an arrow, starting at mean\n",
    "        plt.scatter(grains[:,0], grains[:,1])\n",
    "        plt.arrow(mean[0],mean[1], first_pc[0], first_pc[1], color='red', width=0.051)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
